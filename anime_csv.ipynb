{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 처리 및 분석을 위한 라이브러리\n",
    "import numpy as np  # 수학 연산 및 배열 연산을 위한 라이브러리\n",
    "import pandas as pd  # 데이터 프레임을 다루기 위한 라이브러리\n",
    "\n",
    "# 데이터 시각화를 위한 라이브러리\n",
    "import matplotlib.pyplot as plt  # 그래프 및 차트 그리기\n",
    "import seaborn as sns  # 시각화 기능을 향상시키는 라이브러리\n",
    "\n",
    "# 머신러닝 관련 라이브러리\n",
    "from sklearn.cluster import KMeans  # K-means 클러스터링 알고리즘 (비지도 학습)\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler  # 데이터 전처리를 위한 도구\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer  # TF-IDF 벡터 변환 (텍스트 데이터 벡터화)\n",
    "from sklearn.metrics.pairwise import sigmoid_kernel  # 시그모이드 커널을 이용한 유사도 측정\n",
    "from sklearn.metrics.pairwise import cosine_similarity  # 코사인 유사도를 계산하는 함수\n",
    "\n",
    "# 추천 시스템 관련 라이브러리 (Surprise 라이브러리 사용)\n",
    "from surprise import SVD  # SVD(특이값 분해) 기반 추천 시스템 알고리즘\n",
    "from surprise import Dataset, Reader  # 데이터셋 로딩 및 처리\n",
    "from surprise.model_selection import train_test_split  # 추천 시스템용 데이터 분할\n",
    "from surprise import accuracy  # 추천 시스템 평가 (RMSE 등 측정)\n",
    "\n",
    "# 경고 메시지 무시 (불필요한 경고를 숨기기 위해 사용)\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# 자연어 처리 관련 라이브러리\n",
    "import nltk  # 자연어 처리(NLP)를 위한 라이브러리\n",
    "import re  # 정규 표현식 (문자열 처리)\n",
    "import string  # 문자열 관련 기능 제공\n",
    "from nltk.tokenize import word_tokenize  # 문장을 단어 단위로 토큰화\n",
    "from nltk.corpus import stopwords  # 불용어(의미 없는 단어) 제거\n",
    "from nltk.stem import PorterStemmer  # 어간 추출 (동사의 변형을 정규화)\n",
    "\n",
    "# 실행 시간 측정 (성능 비교 등 활용)\n",
    "import time\n",
    "\n",
    "# 최근접 이웃 알고리즘을 위한 라이브러리\n",
    "from scipy.sparse import csr_matrix  # 희소 행렬(대부분이 0인 행렬) 변환\n",
    "from sklearn.neighbors import NearestNeighbors  # 최근접 이웃 알고리즘 (KNN 등)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "anime = pd.read_csv('./data/anime.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "anime_id      0\n",
       "name          0\n",
       "genre        62\n",
       "type         25\n",
       "episodes      0\n",
       "rating      230\n",
       "members       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anime.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "anime_id    0\n",
       "name        0\n",
       "genre       0\n",
       "type        0\n",
       "episodes    0\n",
       "rating      0\n",
       "members     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anime.dropna(axis=0, inplace=True)\n",
    "anime.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "episodes\n",
       "1      5571\n",
       "2      1075\n",
       "12      810\n",
       "13      571\n",
       "26      514\n",
       "       ... \n",
       "358       1\n",
       "366       1\n",
       "201       1\n",
       "172       1\n",
       "125       1\n",
       "Name: count, Length: 187, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anime.episodes.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count of duplicate anime: 0\n"
     ]
    }
   ],
   "source": [
    "duplicated_anime = anime[anime.duplicated()].shape[0] #.shape[0] → 데이터프레임의 행(row) 개수를 의미\n",
    "#anime[anime.duplicated()] -> duplicated()가 True인 행만 선택해서 새로운 데이터프레임을 만듦.\n",
    "#anime.duplicated() -> 중복된 행인지(True/False) 확인\n",
    "print(f'count of duplicate anime: {duplicated_anime}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    \"\"\"\n",
    "        data preprocessing \n",
    "    \"\"\"\n",
    "    \n",
    "    # to lowercase\n",
    "    text = text.lower()\n",
    "\n",
    "    # remove sybmols and other words\n",
    "    text = re.sub(r'<[^>]*>', '', text) # <html> 같은 태그 제거\n",
    "    text = re.sub(r'http\\S+', '', text) # URL 제거\n",
    "    text = re.sub(r'&quot;', '', text) # 특수 기호 제거\n",
    "    text = re.sub(r'.hack//', '', text) # \".hack//\"같은 패턴 제거\n",
    "    text = re.sub(r'&#039;', '', text) # '&#039;' -> '' (어포스트로피 깨짐 현상 제거)\n",
    "    text = re.sub(r'A&#039;s', '', text) # A&#039;s -> ''\n",
    "    text = re.sub(r'I&#039;', 'I\\'', text) # 'I&#039;' → 'I\\'' (아포스트로피 복구)\n",
    "    text = re.sub(r'&amp;', 'and', text) # '&amp;' → 'and' (HTML 인코딩 복구)\n",
    "  \n",
    "    # remove punctuation\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "\n",
    "    # 4. 숫자 제거 (현재는 주석 처리됨, 필요시 활성화)\n",
    "    # text = re.sub(r'\\d+', '', text)\n",
    "\n",
    "    # 5. 토큰화 (단어 단위로 분리)\n",
    "    # words = word_tokenize(text)\n",
    "\n",
    "    # 6. 불용어 제거 (stopwords)\n",
    "    # stop_words = set(stopwords.words('english'))\n",
    "    # words = [word for word in words if word not in stop_words]\n",
    "\n",
    "    # 7. 어간 추출 (stemming)\n",
    "    # stemmer = PorterStemmer()\n",
    "    # words = [stemmer.stem(word) for word in words]\n",
    "\n",
    "    # 8. 다시 하나의 문자열로 합치기\n",
    "    # text = ' '.join(words)\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "process time:  0.1530613899230957  sec.\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time() #time.time()을 사용하여 코드 실행이 시작되는 시간을 저장\n",
    "anime['name']=anime['name'].apply(clean_text) #df의 \"name\" 컬럼의 모든 값에 clean_text() 적용\n",
    "anime['name'] = anime['name'].apply(clean_text) #anime 데이터프레임에도 동일한 작업 수행\n",
    "end_time = time.time() #실행이 끝나는 시점의 시간 기록\n",
    "elapsed_time = end_time - start_time #실행 시간을 초 단위로 계산 \n",
    "print(\"process time: \", elapsed_time, \" sec.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "anime.to_csv(\"./data/anime_v2.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_mini_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
